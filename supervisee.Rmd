# Classification supervisée

```{r}
jeu_donnees = read.csv("Video_Games_Sales_as_at_22_Dec_2016.csv")

jeu_donnees$User_Score[jeu_donnees$User_Score == "tbd"] <- NA
jeu_donnees$User_Score <- as.numeric(jeu_donnees$User_Score)
jeu_donnees$NA_Sales <- as.numeric(jeu_donnees$NA_Sales)
jeu_donnees$Year_of_Release <- as.numeric(jeu_donnees$Year_of_Release)
jeu_donnees$Name <- make.unique(as.character(jeu_donnees$Name))
jeu_donnees <- na.omit(jeu_donnees) # on enlève les "NA"
head(jeu_donnees)
```

## I) Date de sortie

On ajoute une variable New, qui indique si le jeu est sorti après 2007 (inclus) ou non. On enlève l'année de sortie des jeux qui explique entièrement la variable New, mais également la console, car celle-ci dépent directement de la date. On ne garde que les ventes et les notes.

```{r}
data_num = jeu_donnees
head(data_num)
data_num$New <- as.factor(ifelse(data_num$Year_of_Release >= 2007, 1, 0))
table(data_num$New)
data_num = data_num[,-c(1,2,3,4,5,15,16)]
head(data_num)
```

## Arbre CART

```{r}
library(rpart)
arbre=rpart(New~.,data_num)
```

```{r}
library(rpart.plot)
rpart.plot(arbre, type=4, digits=3,roundint=FALSE)
```

### Arbre optimal

```{r}
set.seed(1)
cp.opt <- arbre$cptable[which.min(arbre$cptable[, "xerror"]), "CP"]
cp.opt
```

```{r}
arbre.opt <- prune(arbre,cp=cp.opt)
#png("arbre_opt_date.png", width = 2000, height = 1500, res = 200)
rpart.plot(arbre.opt, type=4)
#dev.off()
```

### Interprétation

On peut constater que les jeux plus anciens reçoivent peu d'avis, la raison principale est qu'ils ont souvent peu d'utilisateurs. En effet, avec Internet, de plus en plus de personnes s'intéressent aux jeux-videos et leur accès est également accru.

On va regarder si il est possible de deviner si le jeu est récent avec ces données.

## Échantillons

```{r}
set.seed(1)
n <- nrow(data_num)
p <- ncol(data_num)-1
test.ratio <- .2 # ratio of test/train samples
n.test <- round(n*test.ratio)
n.test
tr <- sample(1:n,n.test)
data_num.test <- data_num[tr,]
data_num.train <- data_num[-tr,]

table(data_num.test$New)
```

### RandomForest

```{r}
library("randomForest")
fit_RF <- randomForest(New ~., data = data_num.train)
fit_RF
plot(fit_RF)
# Les deux erreurs sont assez élevées, en particulier les faux positifs de 0 (25%). Il est donc peu probable que le modèle prédisse efficacement l'ancienneté.
```

```{r}
pred_rF = predict(fit_RF, data_num.test)
pred_rf_fix = as.numeric(pred_rF) - 1
Dtest_s = as.numeric(data_num.test$New) - 1
mean(Dtest_s == 1*(pred_rf_fix>0.5))
table(Dtest_s,1*(pred_rf_fix>0.5))
# De manière assez attendue, le taux de bonne prédiction est d'environ 80%. Cela n'est pas très impressionnant même si significativement mieux que le hasard. On peut donc penser que la date de sortie du jeu n'influent pas suffisament sur les données concernant les ventes et les notes pour permettre une prédiction extrèmement fiable.
```

### Régression logistique

```{r}
library(MASS)
res_logist <- glm(New ~ ., family = binomial , data=data_num.train)
```

```{r}
pred_logist = predict(res_logist, newdata=data_num.test , type="response")
mean(Dtest_s == 1*(pred_logist>0.5))
table(Dtest_s,1*(pred_logist>0.5))
# On obtient 70% de réussite, soit pire qu'avec RandomForest.
```

### LDA / QDA

```{r}
res_lda = lda(New~., data=data_num.train)
summary(res_lda)

res_qda = qda(New~., data=data_num.train)
summary(res_qda)
```

```{r}
pred_lda = predict(res_lda, newdata = data_num.test)$posterior[,2] 
pred_qda = predict(res_qda, newdata = data_num.test)$posterior[,2] 

table(1*(pred_lda>0.5),data_num.test$New)
mean(data_num.test$New == 1*(pred_lda>0.5))

table(1*(pred_qda>0.5),data_num.test$New)
mean(data_num.test$New == 1*(pred_qda>0.5))
# La LDA et la QDA on également environ 70% de réussite.
```

### Régression Lasso

```{r}
library("glmnet")
res_Lasso <- glmnet(as.matrix(data_num.train[,-10]), data_num.train$New, family='binomial')
summary(res_Lasso)
```

```{r}
cvLasso <- cv.glmnet(as.matrix(data_num.train[,-c(10)]),data_num.train$New,family="binomial",type.measure = "class")
plot(cvLasso)
log(cvLasso$lambda.min)
coef(res_Lasso, s=cvLasso$lambda.min)
```

```{r}
library(pROC)
pred_logit_lasso=predict(cvLasso, newx = as.matrix(data_num.test[,-10]), s = 'lambda.min', type = "response")
ROC_logit_lasso = roc(data_num.test$New, pred_logit_lasso)
ROC_logit_lasso$auc 
```

```{r}
#pred_logit_lasso
```

```{r}
table(1*(pred_logit_lasso>0.5),data_num.test$New)
mean(data_num.test$New == 1*(pred_logit_lasso>0.5))
# 69 encore
```

### Adaboost

```{r}
library("gbm")
fit.adaboost = gbm(as.numeric(New)-1 ~., data_num.train, distribution = "adaboost")
predict_adaboost = predict.gbm(fit.adaboost,data_num.test)
class_adaboost <- 1*(predict_adaboost >1/2)
mean(data_num.test$New == class_adaboost)
table(class_adaboost, data_num.test$New)
```

## II) Note de la presse

Cette fois on cherche à prédire la note des critiques en fonction des mêmes paramètres que précédemment (plus la date).

```{r}
data_crit = jeu_donnees
head(data_crit)
table(data_crit$Critic_Score)
data_crit = data_crit[,-c(1,2,3,4,5,15,16)]
head(data_crit)
```

## Arbre CART

```{r}
library(rpart)
arbre=rpart(Critic_Score~.,data_crit)
```

```{r}
library(rpart.plot)
rpart.plot(arbre, type=4, digits=3,roundint=FALSE)
```

### Arbre optimal

```{r}
set.seed(1)
cp.opt <- arbre$cptable[which.min(arbre$cptable[, "xerror"]), "CP"]
cp.opt
```

```{r}
arbre.opt <- prune(arbre,cp=cp.opt)
png("arbre_opt_crit.png", width = 2000, height = 1500, res = 200)
rpart.plot(arbre.opt, type=4)
#dev.off()
# Cet arbre ne prend en compte finalement que 3 paramètres en compte : User_Score, User_Count, NA_Sales.
```

### Interprétation

La note de la presse ne semble pas vraiment dépendre du nombre de vente car il n'est pas (ou peu) pris en compte dans l'arbre optimal CART.

On va regarder si cela suffit à prédire efficacement la note de la presse

## Échantillons

```{r}
set.seed(1)
n <- nrow(data_crit)
p <- ncol(data_crit)-1
test.ratio <- .2 # ratio of test/train samples
n.test <- round(n*test.ratio)
n.test
tr <- sample(1:n,n.test)
data_crit.test <- data_crit[tr,]
data_crit.train <- data_crit[-tr,]

table(data_crit.test$Critic_Score)
```

### RandomForest

```{r}
library("randomForest")
fit_RF <- randomForest(Critic_Score ~., data = data_crit.train)
fit_RF
plot(fit_RF)
# Le modèle prévoit environ 90 erreurs pour un grand nombre d'arbres.
```

```{r}
pred_rF = predict(fit_RF, data_crit.test)
pred_rf_fix = as.numeric(pred_rF) - 1
Dtest_s = data_crit.test$Critic_Score
Dtest_s_mean = mean(Dtest_s)
Err = sum((Dtest_s-pred_rf_fix)^2)/sum((Dtest_s-Dtest_s_mean)^2)
Err
Err_diff = mean(abs(Dtest_s-pred_rf_fix))
Err_diff
Err_max = max(Dtest_s-pred_rf_fix)
Err_max
# En moyenne, la prédiction du modèle avec RandomForest se trompe d'un écart de 7.16 points.
```

### Régression gaussienne

```{r}
library("glmnet")
res_Gauss <- glmnet(as.matrix(data_crit.train[,-6]), data_crit.train$Critic_Score, family='gaussian')
summary(res_Gauss)
```

```{r}
cvGauss <- cv.glmnet(as.matrix(data_crit.train[,-6]),data_crit.train$Critic_Score,family="gaussian")
plot(cvGauss)
log(cvGauss$lambda.min)
coef(res_Gauss, s=cvGauss$lambda.min)
```

```{r}
library(pROC)
pred_logit_gauss=predict(cvGauss, newx = as.matrix(data_crit.test[,-6]), s = 'lambda.min', type = "link")
```

```{r}
Err = sum((Dtest_s-pred_logit_gauss)^2)/sum((Dtest_s-Dtest_s_mean)^2)
Err
Err_diff = mean(abs(Dtest_s-pred_logit_gauss))
Err_diff
Err_max = max(Dtest_s-pred_logit_gauss)
Err_max
# En moyenne, la prédiction du modèle avec régression se trompe d'un écart de 7.91 points.
```

### Adaboost

```{r}
library("gbm")
fit.adaboost = gbm(Critic_Score ~., data_crit.train, distribution = "gaussian")
predict_adaboost = predict.gbm(fit.adaboost,data_crit.test)
Err = sum((Dtest_s-predict_adaboost)^2)/sum((Dtest_s-Dtest_s_mean)^2)
Err
Err_diff = mean(abs(Dtest_s-predict_adaboost))
Err_diff
Err_max = max(Dtest_s-predict_adaboost)
Err_max
# En moyenne, la prédiction du modèle avec Adaboost se trompe d'un écart de 7.36 points.
```

### VERDICT :

Le modèle RandomForest est sensiblement meilleur que Adaboost ou la régression linéaire, mais les trois ont de résultats assez proches. On semble donc pourvoir prédire la note de la presse avec une moyenne de 7.16 d'écart. En sachant que la note de la presse peut varier entre 13 et 98 sur notre jeu de données, il s'agit d'un résultat relativement convaincant (en tout cas bien meilleur que le hasard).
